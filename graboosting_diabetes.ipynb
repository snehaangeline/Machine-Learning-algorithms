{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snehaangeline/Machine-Learning-algorithms/blob/main/graboosting_diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69bAP-aqchxM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pyplot\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbxDTCKhcuxJ"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/sample_data/diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ-sMAkPdt3z"
      },
      "outputs": [],
      "source": [
        "X=df.drop('Outcome',axis=1)\n",
        "Y=df.Outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp4Gx0Ipdy9w"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,train_size=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ah_CCxid2tP"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scale = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pJT4PK0d5VN",
        "outputId": "3f57ef1e-8fe9-470e-819a-360d6a3fbaba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(max_depth=10, max_features='auto', n_estimators=200,\n",
              "                           random_state=42)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gbc=GradientBoostingClassifier(n_estimators=200,learning_rate=0.1,random_state=42,max_features='auto',max_depth=10 )\n",
        "gbc.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejA_56PUeAqD",
        "outputId": "c52f795f-6436-4924-b8bd-155f76141956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[68 21]\n",
            " [24 41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.76      0.75        89\n",
            "           1       0.66      0.63      0.65        65\n",
            "\n",
            "    accuracy                           0.71       154\n",
            "   macro avg       0.70      0.70      0.70       154\n",
            "weighted avg       0.71      0.71      0.71       154\n",
            "\n",
            "GBC accuracy is 0.71\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "print(confusion_matrix(y_test, gbc.predict(X_test)))\n",
        "print(classification_report(y_test, gbc.predict(X_test)))\n",
        "print(\"GBC accuracy is %2.2f\" % accuracy_score(y_test, gbc.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cikxhutwsycU",
        "outputId": "9bcb4c91-b21f-48ea-8598-7b6547a7496a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in range(200,2000,200)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpiuceQ-Q3yI"
      },
      "outputs": [],
      "source": [
        "gbc = GradientBoostingClassifier()\n",
        "parameters = {\n",
        "    \"n_estimators\":[5,50,250,500],\n",
        "    \"max_depth\":[1,3,5,7,9],\n",
        "    \"learning_rate\":[0.01,0.1,1,10,100]\n",
        "}\n",
        "\n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [10,15],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5,6],\n",
        "    'min_samples_split': [3,4,5,6],\n",
        "    'n_estimators': [1150, 1200, 1250, 1300,1350]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FCMR8Bu1RDuJ",
        "outputId": "1cbecd56-d7db-4745-c3ef-92c8de0c6337"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
              "             param_grid={'learning_rate': [0.01, 0.1, 1, 10, 100],\n",
              "                         'max_depth': [1, 3, 5, 7, 9],\n",
              "                         'n_estimators': [5, 50, 250, 500]})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "cv = GridSearchCV(gbc,parameters,cv=5)\n",
        "cv.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVIUDY8Vtbl0"
      },
      "outputs": [],
      "source": [
        "model = GradientBoostingClassifier()\n",
        "gbc_random = RandomizedSearchCV(estimator=model,param_distributions = random_grid,\n",
        "                              n_iter = 50, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "gbc_random.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLaxjPb2Nsgz"
      },
      "outputs": [],
      "source": [
        "estimator.get_params().keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zn-dNoow1Ym"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search\n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [10,15],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5,6],\n",
        "    'min_samples_split': [3,4,5,6],\n",
        "    'n_estimators': [1150, 1200, 1250, 1300,1350]\n",
        "}\n",
        "# Create a based model\n",
        "gbc=GradientBoostingClassifier()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = gbc, param_grid = param_grid,\n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjhaQ_pQxs8Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZK_YtJeGhFq"
      },
      "outputs": [],
      "source": [
        "params = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}]\n",
        "\n",
        "clf = GridSearchCV(gbc,params, cv = 10, scoring='accuracy')\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RScUUkC9X5w"
      },
      "outputs": [],
      "source": [
        "print(clf.best_params_)\n",
        "print(clf.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gakDxthBCrp"
      },
      "source": [
        "RANDOM FOREST CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7K0vVnR_P6G"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(n_estimators=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUkMcjQF_VSw"
      },
      "outputs": [],
      "source": [
        "rfc.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ_zN_T7_0Q5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "print(confusion_matrix(y_test, rfc.predict(X_test)))\n",
        "print(classification_report(y_test, rfc.predict(X_test)))\n",
        "print(\"RFC accuracy is %2.2f\" % accuracy_score(y_test, rfc.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4blMigwvAFPD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in range(200,2000,200)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bI6w1RmQAjrB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqDySaYHAtBA"
      },
      "outputs": [],
      "source": [
        "rfc=RandomForestClassifier()\n",
        "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid,\n",
        "                              n_iter = 50, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "rfc_random.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H16iJGYRCl2P"
      },
      "outputs": [],
      "source": [
        "rfc_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq-txr14Cqnw"
      },
      "outputs": [],
      "source": [
        "print(rfc_random.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ATsKfaQC_aa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search\n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [10,15],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5,6],\n",
        "    'min_samples_split': [3,4,5,6],\n",
        "    'n_estimators': [1150, 1200, 1250, 1300,1350]\n",
        "}\n",
        "# Create a based model\n",
        "rfc = RandomForestClassifier()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rfc, param_grid = param_grid,\n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train,y_train)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxa8PI7W60/c/9Kiu1d1zo",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}